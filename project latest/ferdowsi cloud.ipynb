{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4b10e6-da55-4c15-bd44-8bedc1c1e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "weight_decay = 0.0001\n",
    "batch_size = None\n",
    "num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c61b2e5-99b0-46d5-a6f0-b05f34f28ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.load(\"Image_data_per_episode.npy\",mmap_mode='c')\n",
    "episode_length = np.load(\"Episode.npy\",mmap_mode='c')\n",
    "velocity = np.load(\"Velocity.npy\",mmap_mode='c')\n",
    "r_theta_data = np.load(\"R_T_data.npy\",mmap_mode='c')\n",
    "\n",
    "\n",
    "test_image = np.load(\"test_Image.npy\",mmap_mode='c')\n",
    "test_episode_length = np.load(\"test_Episode.npy\",mmap_mode='c')\n",
    "test_velocity = np.load(\"test_velocity.npy\",mmap_mode='c')\n",
    "test_r_theta_data = np.load(\"test_R_T_data.npy\",mmap_mode='c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f8ca78-2828-475a-ab0c-5b3687f61b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout,Dense,Flatten,Input,Activation,Concatenate,Conv2D,Flatten,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16,MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from math import atan\n",
    "\n",
    "#baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "#                input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1cdf3a7-c25b-49f3-883c-ab550f8fc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_length_list = []\n",
    "for i in episode_length:\n",
    "    episode_length_list.append(int(i))\n",
    "    \n",
    "\n",
    "test_episode_length_list = []\n",
    "for i in test_episode_length:\n",
    "    test_episode_length_list.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7b158f-3a90-469b-8819-683b3470b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_indices = np.arange(len(episode_length))\n",
    "\n",
    "# Shuffle the episode indices\n",
    "np.random.shuffle(episode_indices)\n",
    "\n",
    "\n",
    "\n",
    "test_episode_indices = np.arange(len(test_episode_length))\n",
    "\n",
    "# Shuffle the episode indices\n",
    "np.random.shuffle(test_episode_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68ea06a-fb70-4a3d-a3aa-b4e081143648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the Image array into episodes based on the episode_lengths\n",
    "episodes = np.split(image, episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "image = np.concatenate(shuffled_episodes, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "episodes = np.split(test_image, test_episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in test_episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "test_image = np.concatenate(shuffled_episodes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca2357b-6015-436e-a4f0-038ca7d31b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the Image array into episodes based on the episode_lengths\n",
    "episodes = np.split(velocity, episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "velocity = np.concatenate(shuffled_episodes, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "episodes = np.split(test_velocity, test_episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in test_episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "test_velocity = np.concatenate(shuffled_episodes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa1b4eb-fd31-4b9d-81f5-d7e83e7e2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the Image array into episodes based on the episode_lengths\n",
    "episodes = np.split(r_theta_data, episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "r_theta_data = np.concatenate(shuffled_episodes, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "episodes = np.split(test_r_theta_data, test_episode_length_list)[:-1]\n",
    "\n",
    "# Rearrange the episodes based on the shuffled episode_indices\n",
    "shuffled_episodes = [episodes[i] for i in test_episode_indices]\n",
    "\n",
    "# Concatenate the shuffled episodes back into a single array\n",
    "test_r_theta_data = np.concatenate(shuffled_episodes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd40b4b-3fd1-46aa-bbe9-6616a104a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8890dc8a-906b-4f9c-9362-a2a975d130b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Activation , concatenate\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f470fea1-0da5-4bd8-be95-63f63524722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25603, 160, 120, 3) - y_train shape: (25603, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (160, 120, 3)\n",
    "\n",
    "x_train = image\n",
    "y_train = velocity\n",
    "\n",
    "x_test = test_image\n",
    "y_test = test_velocity\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d62bdd-ee40-4288-86ee-8e25047656c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb91d38b-7fd9-48e8-b244-9dd8748c60a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:02:18.772511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:18.813410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:18.813747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:18.815255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 16:02:18.822078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:18.822390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:18.822593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:19.353452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:19.353732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:19.353918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-12 16:02:19.354083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22312 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:00:06.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(\n",
    "    input_shape=(160,120,3),\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=False,\n",
    "    weights='mobilenet_1_0_224_tf_no_top.h5',\n",
    "    input_tensor=None,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True    #!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f5c9c5-92e1-4114-80c5-01793cc29d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ext():\n",
    "        image_inputs = layers.Input(shape=(160,120,3)) #shape=(None, 160, 120, 3))\n",
    "        goal_inputs = layers.Input(shape=(2,))\n",
    "            # Augment data.\n",
    "\n",
    "        g = Dense(32,activation = 'linear')(goal_inputs)\n",
    "        g = Dense(128,activation = 'linear')(g)\n",
    "        g = Dense(512,activation = 'linear')(g)\n",
    "        g = Dense(2048,activation = 'linear')(g)\n",
    "        g = Dense(8192,activation = 'linear')(g)\n",
    "        g = Dense(19200,activation = 'relu')(g)\n",
    "        print(\"kir to hossein\")\n",
    "        g= tf.reshape(g,(-1,160,120,1))\n",
    "        #g=tf.expand_dims(g,axis=0)\n",
    "\n",
    "        conCat = Concatenate()([image_inputs,g])\n",
    "        inp = Conv2D(3,3, padding='same', activation=\"relu\")(conCat)\n",
    "        \n",
    "        \n",
    "        kir_to= base_model(inp)\n",
    "\n",
    "\n",
    "        #inp=tf.expand_dims(inp,axis=0)\n",
    "        \n",
    "\n",
    "        features = Flatten()(kir_to)\n",
    "\n",
    "\n",
    "        \n",
    "        linear_vel = Dense(4096, activation=\"relu\",name = 'first_lin')(features)\n",
    "        linear_vel = Dense(2048, activation=\"relu\")(linear_vel)\n",
    "        linear_vel = Dense(1024, activation=\"relu\")(linear_vel)\n",
    "        linear_vel = Dense(512, activation=\"relu\")(linear_vel)\n",
    "        linear_vel = Dense(128, activation=\"relu\")(linear_vel)\n",
    "        linear_vel = Dense(32, activation=\"relu\")(linear_vel)\n",
    "        linear_vel = Dense(1,)(linear_vel)                        \n",
    "        linear_net =Activation(\"linear\", name=\"linear_output\")(linear_vel)                  \n",
    "                                                                                        \n",
    "                                                                                         \n",
    "        angular_vel = Dense(4096, activation=\"relu\",name = 'first_ang')(features)\n",
    "        angular_vel = Dense(2048, activation=\"relu\")(angular_vel)\n",
    "        angular_vel = Dense(1024, activation=\"relu\")(angular_vel)\n",
    "        angular_vel = Dense(512, activation=\"relu\")(angular_vel)\n",
    "        angular_vel = Dense(128, activation=\"relu\")(angular_vel)\n",
    "        angular_vel = Dense(32, activation=\"relu\")(angular_vel)\n",
    "        angular_vel = Dense(1,)(angular_vel)                        \n",
    "        angular_net =Activation(\"linear\", name=\"angular_output\")(angular_vel)   \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = Model(inputs=[image_inputs,goal_inputs], outputs=[linear_net,angular_net])\n",
    "\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb600052-d7a7-46f3-8cda-1b98b78599de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kir to hossein\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           96          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          4224        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          66048       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2048)         1050624     ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8192)         16785408    ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 19200)        157305600   ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 160, 120, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 160, 120, 1)  0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 160, 120, 4)  0           ['input_2[0][0]',                \n",
      "                                                                  'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 160, 120, 3)  111         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " mobilenet_1.00_160 (Functional  (None, 5, 3, 1024)  3228864     ['conv2d[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 15360)        0           ['mobilenet_1.00_160[0][0]']     \n",
      "                                                                                                  \n",
      " first_lin (Dense)              (None, 4096)         62918656    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " first_ang (Dense)              (None, 4096)         62918656    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2048)         8390656     ['first_lin[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 2048)         8390656     ['first_ang[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         2098176     ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1024)         2098176     ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 512)          524800      ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 512)          524800      ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          65664       ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 128)          65664       ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 32)           4128        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 32)           4128        ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            33          ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            33          ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " linear_output (Activation)     (None, 1)            0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " angular_output (Activation)    (None, 1)            0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 326,445,201\n",
      "Trainable params: 326,423,313\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature = feature_ext()\n",
    "feature.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796883d5-2b24-4a77-8114-fe43349d5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch%2 ==0:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr\n",
    "def run_experiment(model):\n",
    "    lr_planer = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "#######################################################################################################################33    \n",
    "    losses={'linear_output':'mse','angular_output':'mse'}                      #########################################\n",
    "    weight={'linear_output':1,'angular_output':4}                                                                                   ################################\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=losses,\n",
    "        metrics={ 'linear_output':\"mean_squared_error\",'angular_output': \"mean_squared_error\"},loss_weights=weight)\n",
    "    \n",
    "    log_dir = ''\n",
    "    checkpoint_filepath = log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint( \n",
    "        #callback is an object that can perform actions at various stages of training\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=[x_train,r_theta_data],\n",
    "        y=[y_train[:,0,0],y_train[:,1,2]],\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(\n",
    "            [x_test,test_r_theta_data],\n",
    "            [y_test[:,0,0],y_test[:,1,2]]\n",
    "        ),\n",
    "        callbacks=[checkpoint_callback,lr_planer],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    " #   _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "  #  print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "   # print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "    \n",
    "    model.save('')\n",
    "    return history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bfbad-e009-41c4-b870-9e73c6910169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kir to hossein\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:04:01.892351: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5898931200 exceeds 10% of free system memory.\n",
      "2023-06-12 16:04:06.128794: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5898931200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 16:04:13.934394: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-12 16:04:14.109297: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2023-06-12 16:04:15.518719: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-12 16:04:15.519854: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-12 16:04:15.519913: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-06-12 16:04:15.521301: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-12 16:04:15.521416: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 73s 83ms/step - loss: 28534732.0000 - linear_output_loss: 22926686.0000 - angular_output_loss: 1402013.1250 - linear_output_mean_squared_error: 22926686.0000 - angular_output_mean_squared_error: 1402013.1250 - val_loss: 0.3834 - val_linear_output_loss: 0.0143 - val_angular_output_loss: 0.0923 - val_linear_output_mean_squared_error: 0.0143 - val_angular_output_mean_squared_error: 0.0923 - lr: 0.0090\n",
      "Epoch 2/50\n",
      "801/801 [==============================] - 63s 78ms/step - loss: 0.3366 - linear_output_loss: 0.0089 - angular_output_loss: 0.0819 - linear_output_mean_squared_error: 0.0089 - angular_output_mean_squared_error: 0.0819 - val_loss: 0.3802 - val_linear_output_loss: 0.0140 - val_angular_output_loss: 0.0915 - val_linear_output_mean_squared_error: 0.0140 - val_angular_output_mean_squared_error: 0.0915 - lr: 0.0067\n",
      "Epoch 9/50\n",
      "697/801 [=========================>....] - ETA: 7s - loss: 0.3381 - linear_output_loss: 0.0084 - angular_output_loss: 0.0824 - linear_output_mean_squared_error: 0.0084 - angular_output_mean_squared_error: 0.0824"
     ]
    }
   ],
   "source": [
    "freture = feature_ext()\n",
    "history = run_experiment(freture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610130cb-74ce-431b-8d7c-ff7bc83c0c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
