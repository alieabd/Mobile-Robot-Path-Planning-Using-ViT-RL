{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a493338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation , concatenate , Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001e233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (160, 120, 3)\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "image_size = 256  # We'll resize input images to this size\n",
    "patch_size = 32  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 2\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46142bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        \n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8b3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2424c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08213428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim) #Linear Projection Of Patch-Tockens\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e5eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    image_inputs = layers.Input(shape=input_shape) #shape=(None, 32, 32, 3)\n",
    "    goal_inputs = layers.Input(shape=(2,))\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(image_inputs) #shape=(None, 72, 72, 3)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented) #shape=(None, None, 108)\n",
    "    \n",
    "    #Add Goal to Patches\n",
    "    Goal = mlp(goal_inputs,[32,512,3072],dropout_rate=0.05) #shape=(1, 192)\n",
    "    Goal = tf.reshape(Goal,[1,1,3072])\n",
    "\n",
    "    tf.keras.layers.Concatenate(axis=1)([Goal,patches])    \n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches) #shape=(None, 144, 64)\n",
    "    \n",
    "    \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention( #Self Attention mechanism\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        representation = layers.Flatten()(representation)\n",
    "        representation = layers.Dropout(0.3)(representation)\n",
    "        #so far we created the image representation\n",
    "    \n",
    "        # Add MLP.\n",
    "        features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "        print(features.shape)\n",
    "    \n",
    "    # Classify outputs.##############################################################################################\n",
    "    \n",
    "    linear_vel = layers.Dense(512, activation=\"relu\" , name = 'first_lin')(features)\n",
    "    linear_vel = layers.Dense(128, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(32, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    linear_net =Activation(\"linear\", name=\"linear_output\")(linear_vel)                  \n",
    "     \n",
    "     \n",
    "                                                                                         \n",
    "    angular_vel = layers.Dense(512, activation=\"relu\",name = 'first_ang')(features)\n",
    "    angular_vel = layers.Dense(128, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(32, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    angular_net =Activation(\"linear\", name=\"angular_output\")(angular_vel)\n",
    "                                                                                         \n",
    "    \n",
    "    \n",
    "    # Create the Keras model.##############################################################################\n",
    "    model = keras.Model(inputs=[image_inputs,goal_inputs], outputs=[linear_net,angular_net])             \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48662ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Target():\n",
    "    image_inputs = layers.Input(shape=input_shape) #shape=(None, 32, 32, 3)\n",
    "    goal_inputs = layers.Input(shape=(2,))\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(image_inputs) #shape=(None, 72, 72, 3)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented) #shape=(None, None, 108)\n",
    "    \n",
    "    #Add Goal to Patches\n",
    "    Goal = mlp(goal_inputs,[32,512,3072],dropout_rate=0.05) #shape=(1, 192)\n",
    "    Goal = tf.reshape(Goal,[1,1,3072])\n",
    "\n",
    "    tf.keras.layers.Concatenate(axis=1)([Goal,patches])    \n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches) #shape=(None, 144, 64)\n",
    "    \n",
    "    \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention( #Self Attention mechanism\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        representation = layers.Flatten()(representation)\n",
    "        representation = layers.Dropout(0.3)(representation)\n",
    "        #so far we created the image representation\n",
    "    \n",
    "        # Add MLP.\n",
    "        features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "        print(features.shape)\n",
    "    \n",
    "    # Classify outputs.##############################################################################################\n",
    "    \"\"\"\n",
    "    linear_vel = layers.Dense(512, activation=\"relu\" , name = 'first_lin')(features)\n",
    "    linear_vel = layers.Dense(128, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(32, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    linear_net =Activation(\"linear\", name=\"linear_output\")(linear_vel)                  \n",
    "     \n",
    "     \n",
    "                                                                                         \n",
    "    angular_vel = layers.Dense(512, activation=\"relu\",name = 'first_ang')(features)\n",
    "    angular_vel = layers.Dense(128, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(32, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    angular_net =Activation(\"linear\", name=\"angular_output\")(angular_vel)\n",
    "                                                                                         \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the Keras model.##############################################################################\n",
    "    model = keras.Model(inputs=[image_inputs,goal_inputs], outputs=[features])             \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a052ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetModel_actor(model=None,target=None):\n",
    "        weights= model.get_weights()\n",
    "        target_net = target.get_weights()\n",
    "        \n",
    "        for i in range(44,53):\n",
    "\n",
    "            new_weight = weights[i]\n",
    "            target_net[i-44] = new_weight\n",
    " \n",
    "        target.set_weights(target_net)\n",
    " \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b73329ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetModel_back(model=None,target=None):\n",
    "        weights= model.get_weights()\n",
    "        target_net = target.get_weights()\n",
    "        \n",
    "        for i in range(len(target_net)):\n",
    "\n",
    "            new_weight = weights[i]\n",
    "            target_net[i] = new_weight\n",
    " \n",
    "        target.set_weights(target_net)\n",
    " \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d0daafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetModel_reward(model=None,target=None):\n",
    "        weights= model.get_weights()\n",
    "        target_net = target.get_weights()\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "\n",
    "            new_weight = weights[i]\n",
    "            target_net[i] = new_weight\n",
    " \n",
    "        target.set_weights(target_net)\n",
    " \n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75f8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor():\n",
    "    features = layers.Input(shape=(1024,))\n",
    "    \n",
    "    linear_vel = layers.Dense(512, activation=\"relu\" , name = 'first_lin')(features)\n",
    "    linear_vel = layers.Dense(128, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(32, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    linear_net =Activation(\"linear\", name=\"linear_output\")(linear_vel)                  \n",
    "     \n",
    "     \n",
    "                                                                                         \n",
    "    angular_vel = layers.Dense(512, activation=\"relu\",name = 'first_ang')(features)\n",
    "    angular_vel = layers.Dense(128, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(32, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    angular_net =Activation(\"linear\", name=\"angular_output\")(angular_vel)\n",
    "    \n",
    "    model = keras.Model(inputs = features , outputs = [linear_vel,angular_vel])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e252f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_reward_func(in_Dims=1024):\n",
    "    features= keras.Input(shape=(in_Dims,))\n",
    "    \n",
    "    linear_vel = layers.Dense(512, activation=\"relu\" , name = 'first_lin')(features)\n",
    "    linear_vel = layers.Dense(128, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(32, activation=\"relu\")(linear_vel)\n",
    "    linear_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    linear_net =Activation(\"linear\", name=\"linear_output\")(linear_vel)                  \n",
    "     \n",
    "     \n",
    "                                                                                         \n",
    "    angular_vel = layers.Dense(512, activation=\"relu\",name = 'first_ang')(features)\n",
    "    angular_vel = layers.Dense(128, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(32, activation=\"relu\")(angular_vel)\n",
    "    angular_vel = layers.Dense(1,)(linear_vel)                        \n",
    "    angular_net =Activation(\"linear\", name=\"angular_output\")(angular_vel)\n",
    "    \n",
    "    ConCat = concatenate([linear_net , angular_net] , axis = -1)\n",
    "    \n",
    "    x=Dense(32,activation=\"relu\")(ConCat)\n",
    "    x=Dense(16,activation=\"relu\")(x)\n",
    "    x=Dense(1)(x)\n",
    "    \n",
    "    out=Activation(\"linear\",name=\"rew_out\")(x)\n",
    "    \n",
    "    \n",
    "    reward_net = keras.Model(inputs=features,outputs=out,name=\"TPr_net\")\n",
    "    \n",
    "    return reward_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14381b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'D:\\\\Ali_Reza\\\\kir to hossein\\\\model\\\\'\n",
    "checkpoint_filepath = log_dir + 'ep120-loss0.195-val_loss0.314.h5'\n",
    "model = create_vit_classifier()\n",
    "model.load_weights(checkpoint_filepath)\n",
    "print('[info] .... weight loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f40eec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "back_bone = Target()\n",
    "backBone = updateTargetModel_back(model = model , target = back_bone)\n",
    "path_1 = log_dir + 'Back_bone.h5'\n",
    "backBone.save_weights(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00cd1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = log_dir + 'actor.h5'\n",
    "actor = actor()\n",
    "Actor = updateTargetModel_actor(model=model,target=actor)\n",
    "Actor.save_weights(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93e45f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3 = log_dir + 'reward.h5'\n",
    "reward=trainable_reward_func()\n",
    "reward_net = updateTargetModel_reward(model=Actor,target=reward)\n",
    "reward_net.save_weights(path_3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6db09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_net = updateTargetModel_2(tau=1,model=acc,target=reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c509f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath_3 = log_dir + 'part3_new.h5'\n",
    "reward_net.save_weights(checkpoint_filepath_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ffa07624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "232d02ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b88eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca0fa390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30a0580d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046607c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
